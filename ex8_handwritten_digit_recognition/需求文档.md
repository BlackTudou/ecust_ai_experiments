1.数据集准备：使用 MNIST 手写数字数据集（60000 张训练图，10000 张测试图，每张图为 28×28 灰度图，共 10 个类别），通过框架自带接口加载数据集；​
2.图像数据预处理：​
 - 数据格式转换：将图像数据转换为框架支持的张量格式；​
 - 归一化：将像素值从 [0,255] 转换为 [0,1]，加速模型训练；​
 - 数据增强（可选）：如随机旋转、平移、翻转等，提高模型泛化能力；
3.构建 CNN 模型（基于 LeNet-5 改进）：​
 - 使用 PyTorch 定义模型结构：输入层（28×28×1）→卷积层（32 个 3×3 卷积核，激活函数 ReLU）→池化层（2×2 最大池化）→卷积层（64 个 3×3 卷积核，激活函数 ReLU）→池化层（2×2 最大池化）→扁平化层→全连接层（128 个神经元，激活函数 ReLU）→Dropout 层（ dropout rate=0.5，防止过拟合）→输出层（10 个神经元，激活函数 Softmax）；
 - 查看模型结构：打印模型的层信息、参数数量，理解各层的作用；​
4.模型训练与监控：​
 - 配置训练参数：优化器选择 Adam（学习率 0.001），损失函数选择稀疏分类交叉熵（适用于整数标签），评估指标选择准确率；​
 - 训练模型：设置 epochs=10、batch_size=32，使用训练集训练模型，同时用测试集作为验证集监控模型性能，记录训练过程中的训练准确率、验证准确率、训练损失、验证损失；​
 - 可视化训练过程：绘制训练准确率与验证准确率曲线、训练损失与验证损失曲线，分析模型是否存在过拟合（如验证准确率上升后下降，验证损失下降后上升）；​
5.模型评估与预测：​
 - 在测试集上评估模型性能，计算测试准确率，查看混淆矩阵，分析模型在不同类别数字上的分类效果；​
 - 随机选取测试集中的几张图像，使用训练好的模型进行预测，对比预测结果与真实标签，直观观察模型预测效果；​
6.模型优化（可选）：​
 - 调整模型结构（如增加卷积层数量、改变卷积核大小、调整全连接层神经元数量）；​
 - 调整训练参数（如学习率、batch_size、epochs、dropout rate）；​
 - 应用数据增强技术，对比优化前后模型的性能变化；